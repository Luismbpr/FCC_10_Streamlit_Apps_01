{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac381e95-1040-44dd-830d-caf9b3d1eecf",
   "metadata": {},
   "source": [
    "### Web App Test 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa202d-2ad5-4b28-af76-d1ca75a5598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "st.write(\"\"\"\n",
    "California Housing Data App\n",
    "#### This Web App predicts the Median House Value given a set of Parameters\n",
    "\"\"\")\n",
    "\n",
    "## df and replacing nan values with median\n",
    "## Also dropping class label\n",
    "calif_raw = pd.read_csv('./Projects/App_009_001/App_009_001_Exported/Data/housing.csv')\n",
    "calif_raw['total_bedrooms'] = calif_raw['total_bedrooms'].replace({np.nan:calif_raw['total_bedrooms'].median()})\n",
    "X = calif_raw.drop(columns=['median_house_value'], axis=1)\n",
    "\n",
    "##Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "##       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "##       'ocean_proximity'],\n",
    "##      dtype='object')\n",
    "\n",
    "def user_input_features():\n",
    "    ocean_proximity = st.sidebar.selectbox('ocean_proximity', ('NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'))##\n",
    "    longitude = st.sidebar.slider('longitude', X['longitude'].min(), X['longitude'].max(), X['longitude'].mean())\n",
    "    latitude = st.sidebar.slider('latitude', X['latitude'].min(), X['latitude'].max(), X['latitude'].mean())\n",
    "    housing_median_age = st.sidebar.slider('housing_median_age', X['housing_median_age'].min(), X['housing_median_age'].max(), X['housing_median_age'].mean())\n",
    "    total_rooms = st.sidebar.slider('total_rooms', X['total_rooms'].min(), X['total_rooms'].max(), X['total_rooms'].mean())\n",
    "    total_bedrooms = st.sidebar.slider('total_bedrooms', X['total_bedrooms'].min(), X['total_bedrooms'].max(), X['total_bedrooms'].mean())\n",
    "    population = st.sidebar.slider('population', X['population'].min(), X['population'].max(), X['population'].mean())\n",
    "    households = st.sidebar.slider('households', X['households'].min(), X['households'].max(), X['households'].mean())\n",
    "    median_income = st.sidebar.slider('median_income', X['median_income'].min(), X['median_income'].max(), X['median_income'].mean())\n",
    "    data = {'longitude':longitude,\n",
    "            'latitude':latitude,\n",
    "            'housing_median_age':housing_median_age,\n",
    "            'total_rooms':total_rooms,\n",
    "            'total_bedrooms':total_bedrooms,\n",
    "            'population':population,\n",
    "            'households':households,\n",
    "            'median_income':median_income,\n",
    "            'ocean_proximity':ocean_proximity}\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    return features\n",
    "input_df = user_input_features()\n",
    "\n",
    "################################################################################################################################################################\n",
    "## Opening raw csv\n",
    "calif_raw02 = pd.read_csv('./Projects/App_009_001/App_009_001_Exported/Data/housing.csv')\n",
    "\n",
    "## Replacing NaN with median values\n",
    "calif_raw02['total_bedrooms'] = calif_raw02['total_bedrooms'].replace({np.nan:calif_raw02['total_bedrooms'].median()})\n",
    "\n",
    "st.write(\"\"\"calif_raw02\"\"\")\n",
    "st.write(calif_raw02.head(2))\n",
    "\n",
    "calif_features = calif_raw02.drop(columns=['median_house_value'], axis=1)\n",
    "\n",
    "df = pd.concat([input_df, calif_features], axis=0)\n",
    "### Preprocessing phase\n",
    "\n",
    "#calif_features['ocean_proximity'].unique()\n",
    "#Result\n",
    "##array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'], dtype=object)\n",
    "#calif_features\n",
    "\n",
    "## Creating dummy variables for ocean_proximity\n",
    "encode = ['ocean_proximity']\n",
    "dummies_01 = pd.get_dummies(data=df[encode], prefix=None, prefix_sep = '_', dummy_na = False, columns = None, sparse = False, drop_first = False, dtype = None).astype('int')\n",
    "\n",
    "#dummies_01.columns## Column names were changed so I need to change the names to the feature columns used to train the model\n",
    "dummies_01 = dummies_01.rename(mapper={'ocean_proximity_<1H OCEAN':'<1H OCEAN',\n",
    "                            'ocean_proximity_INLAND':'INLAND',\n",
    "                            'ocean_proximity_ISLAND':'ISLAND',\n",
    "                            'ocean_proximity_NEAR BAY':'NEAR BAY',\n",
    "                            'ocean_proximity_NEAR OCEAN':'NEAR OCEAN'}, axis=1)\n",
    "\n",
    "#dummies_01\n",
    "\n",
    "\n",
    "\n",
    "## Dropping original feature column of all the dummy variables created\n",
    "features_float_01 = df.drop(columns=calif_features[encode], axis=1)\n",
    "#features_float_01\n",
    "\n",
    "## I have features_float_01 which is All features except dummy variables and without Y class label\n",
    "## I have dummy variables\n",
    "## I have the user input dataframe\n",
    "## Concatenating features_float_01 and dummy variables\n",
    "\n",
    "\n",
    "df = pd.concat(objs=[features_float_01, dummies_01], axis=1)\n",
    "df = df[:1]\n",
    "\n",
    "##################################################################\n",
    "\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "### Main Panel\n",
    "\n",
    "### Print Specified Input Parameters\n",
    "st.header('Specified Input Parameters')\n",
    "## Show DataFrame\n",
    "st.write(df)\n",
    "st.write('---')\n",
    "\n",
    "## Open ML Model - Regression Model\n",
    "### Reading the Model\n",
    "load_reg = pickle.load(open('./Projects/App_009_001/App_009_001_Exported/Data/Saved_Models/Model_calif_housing_forest.pkl', 'rb'))\n",
    "\n",
    "## Apply model to make prediction\n",
    "model_prediction = load_reg.predict(df)\n",
    "\n",
    "st.subheader('Prediction')\n",
    "st.write(model_prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.write('---')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "\n",
    "\n",
    "st.write('### Resources:')\n",
    "st.write(\"\"\"\n",
    "         [Data Source Downloaded From Kaggle - dhirajnirne](https://www.kaggle.com/datasets/dhirajnirne/california-housing-data)\\n\n",
    "         [Data Source From Kaggle - darshanprabhu09](https://www.kaggle.com/datasets/darshanprabhu09/california-housing-dataset)\\n\n",
    "         [Streamlit](https://streamlit.io/)\n",
    "         \"\"\")\n",
    "\n",
    "st.write('###### *Code based on [Free Code Camp](https://www.freecodecamp.org/). Special Thanks to Free Code Camp and instructor Chanin Nantasenamat*')\n",
    "st.write('##### Thank you to all of you who make information and knowledge available for free.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3839af-b8b3-494a-9cc7-01a61cda98d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69b793f-861e-4c2d-b72a-ee0b64301e2f",
   "metadata": {},
   "source": [
    "# Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d692c3-f82d-4711-985f-942b5de2c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is working now\n",
    "################################################################################################################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "st.write(\"\"\"\n",
    "California Housing Data App\n",
    "#### This Web App predicts the Median House Value given a set of Parameters\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "## Opening raw csv\n",
    "#calif_raw = pd.read_csv('/Users/luis/Documents/Programming/Courses_Programming/FCC_Build_12_DS_Apps_Python_Streamlit/venv_FCC_Build_12_DS_Apps_Python_Streamlit_310/Projects/App_009_002/App_009_002_Data/housing.csv')\n",
    "\n",
    "## Replacing NaN with median values\n",
    "#calif_raw['total_bedrooms'] = calif_raw['total_bedrooms'].replace({np.nan:calif_raw['total_bedrooms'].median()})\n",
    "#calif_features = calif_raw.drop(columns=['median_house_value'], axis=1)\n",
    "\n",
    "#df = pd.concat([calif_features], axis=0)\n",
    "\n",
    "### Preprocessing phase\n",
    "\n",
    "#calif_features['ocean_proximity'].unique()\n",
    "#Result\n",
    "##array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'], dtype=object)\n",
    "#calif_features\n",
    "\n",
    "## Creating dummy variables for ocean_proximity\n",
    "#encode = ['ocean_proximity']\n",
    "#dummies_01 = pd.get_dummies(data=df[encode], prefix=None, prefix_sep = '_', dummy_na = False, columns = None, sparse = False, drop_first = False, dtype = None).astype('int')\n",
    "\n",
    "#dummies_01.columns## Column names were changed so I need to change the names to the feature columns used to train the model\n",
    "#dummies_01.rename(mapper={'ocean_proximity_<1H OCEAN':'<1H OCEAN',\n",
    "#                            'ocean_proximity_INLAND':'INLAND',\n",
    "#                            'ocean_proximity_ISLAND':'ISLAND',\n",
    "#                            'ocean_proximity_NEAR BAY':'NEAR BAY',\n",
    "#                            'ocean_proximity_NEAR OCEAN':'NEAR OCEAN'}, axis=1, inplace=True)\n",
    "#dummies_01\n",
    "\n",
    "## Dropping original feature column of all the dummy variables created\n",
    "#features_float_01 = df.drop(columns=calif_features[encode], axis=1)\n",
    "#features_float_01\n",
    "\n",
    "## I have features_float_01 which is All features except dummy variables and without Y class label\n",
    "## I have dummy variables\n",
    "## I have the user input dataframe\n",
    "## Concatenating features_float_01 and dummy variables\n",
    "\n",
    "\n",
    "#df = pd.concat(objs=[features_float_01, dummies_01], axis=1)\n",
    "#df = df[:1]\n",
    "\n",
    "st.write(\"\"\"\n",
    "##### Special Thanks to all who make learning possible by making information, datasets and learning resources freely available.\n",
    "\"\"\")\n",
    "\n",
    "## df and replacing nan values with median\n",
    "## Also dropping class label\n",
    "calif_raw = pd.read_csv('./Projects/App_009_001/App_009_001_Exported/Data/housing.csv')\n",
    "calif_raw['total_bedrooms'] = calif_raw['total_bedrooms'].replace({np.nan:calif_raw['total_bedrooms'].median()})\n",
    "X = calif_raw.drop(columns=['median_house_value'], axis=1)\n",
    "\n",
    "##Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "##       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "##       'ocean_proximity'],\n",
    "##      dtype='object')\n",
    "\n",
    "def user_input_features():\n",
    "    ocean_proximity = st.sidebar.selectbox('ocean_proximity', ('NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'))##\n",
    "    longitude = st.sidebar.slider('longitude', X['longitude'].min(), X['longitude'].max(), X['longitude'].mean())\n",
    "    latitude = st.sidebar.slider('latitude', X['latitude'].min(), X['latitude'].max(), X['latitude'].mean())\n",
    "    housing_median_age = st.sidebar.slider('housing_median_age', X['housing_median_age'].min(), X['housing_median_age'].max(), X['housing_median_age'].mean())\n",
    "    total_rooms = st.sidebar.slider('total_rooms', X['total_rooms'].min(), X['total_rooms'].max(), X['total_rooms'].mean())\n",
    "    total_bedrooms = st.sidebar.slider('total_bedrooms', X['total_bedrooms'].min(), X['total_bedrooms'].max(), X['total_bedrooms'].mean())\n",
    "    population = st.sidebar.slider('population', X['population'].min(), X['population'].max(), X['population'].mean())\n",
    "    households = st.sidebar.slider('households', X['households'].min(), X['households'].max(), X['households'].mean())\n",
    "    median_income = st.sidebar.slider('median_income', X['median_income'].min(), X['median_income'].max(), X['median_income'].mean())\n",
    "    data = {'longitude':longitude,\n",
    "            'latitude':latitude,\n",
    "            'housing_median_age':housing_median_age,\n",
    "            'total_rooms':total_rooms,\n",
    "            'total_bedrooms':total_bedrooms,\n",
    "            'population':population,\n",
    "            'households':households,\n",
    "            'median_income':median_income,\n",
    "            'ocean_proximity':ocean_proximity}\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    return features\n",
    "input_df = user_input_features()\n",
    "\n",
    "################################################################################################################################################################\n",
    "## Opening raw csv\n",
    "calif_raw = pd.read_csv('./Projects/App_009_001/App_009_001_Exported/Data/housing.csv')\n",
    "\n",
    "## Replacing NaN with median values\n",
    "calif_raw['total_bedrooms'] = calif_raw['total_bedrooms'].replace({np.nan:calif_raw['total_bedrooms'].median()})\n",
    "calif_features = calif_raw.drop(columns=['median_house_value'], axis=1)\n",
    "\n",
    "df = pd.concat([input_df, calif_features], axis=0)\n",
    "\n",
    "### Preprocessing phase\n",
    "\n",
    "#calif_features['ocean_proximity'].unique()\n",
    "#Result\n",
    "##array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'], dtype=object)\n",
    "#calif_features\n",
    "\n",
    "## Creating dummy variables for ocean_proximity\n",
    "encode = ['ocean_proximity']\n",
    "dummies_01 = pd.get_dummies(data=df[encode], prefix=None, prefix_sep = '_', dummy_na = False, columns = None, sparse = False, drop_first = False, dtype = None).astype('int')\n",
    "\n",
    "dummies_01.columns## Column names were changed so I need to change the names to the feature columns used to train the model\n",
    "dummies_01.rename(mapper={'ocean_proximity_<1H OCEAN':'<1H OCEAN',\n",
    "                            'ocean_proximity_INLAND':'INLAND',\n",
    "                            'ocean_proximity_ISLAND':'ISLAND',\n",
    "                            'ocean_proximity_NEAR BAY':'NEAR BAY',\n",
    "                            'ocean_proximity_NEAR OCEAN':'NEAR OCEAN'}, axis=1, inplace=True)\n",
    "dummies_01\n",
    "\n",
    "## Dropping original feature column of all the dummy variables created\n",
    "features_float_01 = df.drop(columns=calif_features[encode], axis=1)\n",
    "#features_float_01\n",
    "\n",
    "## I have features_float_01 which is All features except dummy variables and without Y class label\n",
    "## I have dummy variables\n",
    "## I have the user input dataframe\n",
    "## Concatenating features_float_01 and dummy variables\n",
    "\n",
    "\n",
    "df = pd.concat(objs=[features_float_01, dummies_01], axis=1)\n",
    "df = df[:1]\n",
    "\n",
    "##################################################################\n",
    "\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\n",
    "### Main Panel\n",
    "\n",
    "### Print Specified Input Parameters\n",
    "st.header('Specified Input Parameters')\n",
    "## Show DataFrame\n",
    "st.write(df)\n",
    "st.write('---')\n",
    "\n",
    "## Open ML Model - Regression Model\n",
    "### Reading the Model\n",
    "load_reg = pickle.load(open('./Projects/App_009_001/App_009_001_Exported/Data/Saved_Models/Model_calif_housing_forest.pkl', 'rb'))\n",
    "\n",
    "\n",
    "## Apply model to make prediction\n",
    "model_prediction = load_reg.predict(df)\n",
    "\n",
    "st.subheader('Prediction')\n",
    "st.write(model_prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.write('---')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "st.write('')\n",
    "\n",
    "\n",
    "st.write('### Resources:')\n",
    "st.write(\"\"\"\n",
    "         [Data Source Downloaded From Kaggle - dhirajnirne](https://www.kaggle.com/datasets/dhirajnirne/california-housing-data)\\n\n",
    "         [Data Source From Kaggle - darshanprabhu09](https://www.kaggle.com/datasets/darshanprabhu09/california-housing-dataset)\\n\n",
    "         [Streamlit](https://streamlit.io/)\n",
    "         \"\"\")\n",
    "\n",
    "st.write('###### *Code based on [Free Code Camp](https://www.freecodecamp.org/). Special Thanks to Free Code Camp and instructor Chanin Nantasenamat*')\n",
    "st.write('##### Thank you to all of you who make information and knowledge available for free.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e3f47-2688-4d45-92c3-1ac1fb656fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv_FCC_Build_12_DS_Apps_Python_Streamlit_310] *",
   "language": "python",
   "name": "conda-env-venv_FCC_Build_12_DS_Apps_Python_Streamlit_310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
